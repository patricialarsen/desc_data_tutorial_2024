{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967624c1-dd04-4747-9781-6ce89b6d1594",
   "metadata": {},
   "source": [
    "## Validation plot answer sheet\n",
    "\n",
    "Compute a plot of the position-dependent PSF size (we'll define this as the trace we computed in the last notebook)\n",
    "* Make the band an input argument, and run plots for the g-band and the i-band\n",
    "\n",
    "Hints \n",
    "* scipy.binned_statistic_2d is the function I like to use for this\n",
    "* You can use the code for the data read you used last challenge\n",
    "* If you were reading large amounts of data and don't want to repeat the read, just pass the data in through your input dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ac947-3d96-448c-9e5c-75fd2692f21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(0,'/global/cfs/projectdirs/lsst/groups/SRV/gcr-catalogs-test')\n",
    "import GCRCatalogs\n",
    "sys.path.insert(0,'/global/cfs/projectdirs/lsst/groups/SRV/descqa')\n",
    "import descqa\n",
    "import glob\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63c906-9b0c-4e51-a730-71c701941dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from descqa.base import BaseValidationTest, TestResult\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "from scipy.stats import binned_statistic_2d as bs2d\n",
    "def trace(ixx,ixy,iyy):\n",
    "    return (ixx+iyy)\n",
    "\n",
    "    \n",
    "class Tutorial3(BaseValidationTest):\n",
    "    \"\"\"\n",
    "    validation test to plot RA/DEC\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs): #pylint: disable=W0231\n",
    "        # get the inputs\n",
    "        self.ra = kwargs.get('ra')\n",
    "        self.dec = kwargs.get('dec')\n",
    "        self.band = kwargs.get('band')\n",
    "        self.catalog_filters = kwargs.get('catalog_filters', [])\n",
    "        self.quantities =  kwargs.get('quantities', [])\n",
    "\n",
    "\n",
    "\n",
    "    def run_on_single_catalog(self, catalog_instance, catalog_name, output_dir):\n",
    "\n",
    "\n",
    "        if not catalog_instance.has_quantities([self.ra, self.dec]):\n",
    "            return TestResult(skipped=True)\n",
    "        filters=[]\n",
    "        for i, filt in enumerate(self.catalog_filters):\n",
    "            filters.append(filt)\n",
    "\n",
    "            \n",
    "        # read in the data \n",
    "        data = catalog_instance.get_quantities(self.quantities,filters=filters, return_iterator=False)\n",
    "        \n",
    "        data['T_PSF'] = trace(data[self.band+'_ixxPSF'],data[self.band+'_ixyPSF'],data[self.band+'_iyyPSF'])\n",
    "        \n",
    "        plt.title(self.band+'-band PSF size variation')\n",
    "        val, xedge, yedge, bincount = bs2d(data[\"coord_ra\"],data[\"coord_dec\"],data['T_PSF'],statistic='mean',bins=100)\n",
    "        plt.imshow(val,extent=[xedge[0],xedge[-1],yedge[0],yedge[-1]])\n",
    "        plt.colorbar()\n",
    "        plt.xlabel('RA (degrees)')\n",
    "        plt.ylabel('dec (degrees)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'test_histogram.png'))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        return TestResult(inspect_only=True, summary='made a histogram to inspect!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4fb369-68b2-43fc-94cb-6b14c4289e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "band = 'g'\n",
    "dict_config = {}\n",
    "dict_config['ra'] = 'coord_ra'\n",
    "dict_config['dec'] = 'coord_dec'\n",
    "dict_config['band'] = band\n",
    "dict_config['quantities'] = [\"coord_ra\",\"coord_dec\", band+\"_ixxPSF\", band+\"_ixyPSF\", band+\"_iyyPSF\",band+\"_cModelFlux\"]\n",
    "dict_config['catalog_filters'] =  ['detect_isPrimary','refExtendedness==1']\n",
    "\n",
    "\n",
    "catalog = 'lsst_object'\n",
    "catalog_instance =  GCRCatalogs.load_catalog(catalog)   \n",
    "output_dir_this = './test_direc'  \n",
    "\n",
    "\n",
    "validation3 = Tutorial3(**dict_config)\n",
    "test_result = validation3.run_on_single_catalog(catalog_instance, catalog, output_dir_this)\n",
    "\n",
    "for image in glob.glob( output_dir_this + '/*.png'):\n",
    "    print(image)\n",
    "    display(Image.open(image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506cdb0-4a44-4ed0-b353-47267492692a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Challenges!\n",
    "\n",
    "Okay you should have everything you need to get started looking at and validating the data. Go ahead and make your own plots! \n",
    "\n",
    "I have some suggestions below that the SRV group would love to get some new validation tests drafted for, but anything you or your working group wants to know about the data before it goes through an analysis pipeline is fair game! Or just test out using the DP0.2 data for your own analysis \n",
    "\n",
    "Some FAQs:\n",
    "* There are no photometric redshifts available for this data at this part of the pipleline, see the RAIL tutorial for more details on those\n",
    "* There are no metadetect shears available due to development timelines, however HSM moments are available in the catalog\n",
    "* If you want direct comparison tests we can match to the truth catalog for DP0.2 (and with SSI catalogs for testing), I've provided some code below to get you a matched catalog for this tract "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1965bd60-6173-44ba-b56a-a8ea3dbdf7bd",
   "metadata": {},
   "source": [
    "## Tasks! \n",
    "\n",
    "* Estimate the 5-sigma limiting magnitude (using the psfFlux and definitions as described in https://dmtn-296.lsst.io/) and make a plot of the average value over RA/dec\n",
    "    * Repeat for all bands (grizuy) \n",
    "* Inspect the cModel magnitudes, calib magnitudes and gaap magnitudes and colors against the truth values\n",
    "    * What conclusions can you draw about the best colors to use?\n",
    "    * Do these agree with the suggestions noted in the photometry flags section of https://lsstdesc.org/srv-dp02/tutorials/Rubin/tutorial7_SRV_releases.html ?\n",
    "* Find a few of the brightest stars, using extendedness and magnitude cuts. Look for the RA/dec position of these and plot the galaxy density in this location. What do you see?\n",
    "    * Extra credit exercise for those with DP0 delegate accounts, use the tutorials to find the tract/patch of this co-ordinate and locate and plot the deepcoadd image for this area\n",
    "* Compare the gaap photometry for different apertures including the optimal aperture\n",
    "    * Look through here to understand the method: https://arxiv.org/pdf/1507.00738\n",
    "    * Run the srv_gaap validation code on the dp02_object_single_tract catalog (https://github.com/LSSTDESC/descqa/blob/SRV/descqa/srv_gaap.py) and see if our results agree\n",
    "    * Have a look [here](https://lsstdesc.org/srv-dp02/tutorials/Rubin/tutorial7_SRV_releases.html) and the linked documentation. Do you see hints of this issue when looking at the data? How can we expand our testing to find this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9dcee1-a5a7-42e0-bda8-e28a2cc5eabc",
   "metadata": {},
   "source": [
    "## Truth match FAQ\n",
    "\n",
    "Some of these tasks require you to match against the truth. This requires a bit of table manipulation and requires you to know data locations and matching IDs so I'm going to put some code here so you can get the matched table and get going!\n",
    "\n",
    "First we get the paths of a truth summary and the match to the objectTables. Now these are actually slightly different than you'll see in the [schema](https://sdm-schemas.lsst.io/dp02.html#MatchesTruth.match_chisq) because we're using the DC2 truth tables rather than the DP0.2 ones. But the input galaxies are the same so we can select on galaxies and then use this to match.  \n",
    "\n",
    "TLDR; Run the below and use matched_table for your matched catalog. Look at truth_pandas.keys() for the values you have easy access to - more complex inputs (e.g. shapes) require a further match to the cosmodc2 catalogs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723e6d3-c3c1-4b1d-b46b-5df57cb1fdf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_truth = '/global/cfs/projectdirs/lsst/shared/DC2-prod/Run2.2i/truth/truth_merged_summary_v1-0-0/raw/truth_tract4850.parquet'\n",
    "path_truth_match = '/global/cfs/projectdirs/lsst/shared/rubin/DP0.2/match_ref_truth_summary_objectTable/match_ref_truth_summary_objectTable_tract_4850_DC2_u_ctslater_matchObjectToTruth_w22_20220527T164747Z.parq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a36c1-aac7-4786-849b-c18480dcfa09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyarrow import dataset as ds\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "# let's read in the truth tables and the matching tables  - we ignore metadata here because sometimes it \n",
    "# converts an apparent ID column into the indexing and suppresses it\n",
    "truth = ds.dataset(path_truth)\n",
    "match = ds.dataset(path_truth_match)\n",
    "truth_pandas = truth.to_table().to_pandas(ignore_metadata=True)\n",
    "match_pandas = match.to_table().to_pandas(ignore_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc314b-8f2e-4de8-9427-94ad3860ca42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can look at the keys to confirm the schema\n",
    "print(truth_pandas.keys())\n",
    "print(match_pandas.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3779f7f9-72a2-4042-85ab-cfc7ff27b413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now pandas doesn't like matching on int64s so we will create a string id to make it happy, \n",
    "# and filter out those non-galaxy truth objects\n",
    "match_pandas['id_str'] = match_pandas['id'].astype('str')\n",
    "truth_gals = truth_pandas[truth_pandas['truth_type']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f30c0-a22b-4847-8e18-e02d3e6bf7b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# finally we also can't forget that we need the object catalog\n",
    "catalog = 'lsst_object'\n",
    "catalog_instance =  GCRCatalogs.load_catalog(catalog)   \n",
    "sources = [parquet_data.path for parquet_data in catalog_instance._datasets]\n",
    "dataset = ds.dataset(sources)\n",
    "dataset = dataset.to_table().to_pandas(ignore_metadata=True) # otherwise it'll suppress objectID\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f984c-8f13-4961-8aa6-6604c39dae9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's do a merge - this requires objectID to be unique, but multiple object IDs can match to the same truth object\n",
    "matched_table = pandas.merge(truth_gals,match_pandas,how='inner',left_on='id_string', right_on='id_str', sort=False, suffixes=('_truth','_match'),validate='one_to_many')\n",
    "matched_table = pandas.merge(dataset,matched_table,how='inner',left_on='objectId', right_on='match_objectId', sort=False, suffixes=('_object',''),validate='one_to_many')\n",
    "# the suffixes add a suffix to identically named quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127076cc-d6b5-412d-8260-6714665b341c",
   "metadata": {},
   "source": [
    "Note that the truth matches aren't unique here, so you can further filter them by the chi squared value for the match if you want a better match - let's do a quick check of our match up to make sure the matches are at the same position!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34eaaa-ab90-47ac-b783-c2e5bbe75e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('catalog positions')\n",
    "plt.hist2d(matched_table['coord_ra'],matched_table['coord_dec'],bins=100)\n",
    "plt.show()\n",
    "plt.title('truth positions')\n",
    "plt.hist2d(matched_table['ra'],matched_table['dec'],bins=100)\n",
    "plt.show()\n",
    "plt.title('positional differences')\n",
    "plt.hist(matched_table['coord_ra']-matched_table['ra'],bins=100)\n",
    "plt.hist(matched_table['coord_dec']-matched_table['dec'],bins=100)\n",
    "plt.xlabel('degrees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d196bf-ff87-479a-ace4-feaaac8169e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-python",
   "language": "python",
   "name": "desc-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
